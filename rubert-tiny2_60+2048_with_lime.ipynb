{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "7yNx3-x8ZdAP"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from transformers import AdamW, get_linear_schedule_with_warmup\n",
    "import torch\n",
    "from transformers import AutoTokenizer\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scibox import switch_to_scibox, switch_to_huggingface\n",
    "switch_to_huggingface()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: openpyxl in /usr/local/lib/python3.10/dist-packages (3.1.2)\n",
      "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.10/dist-packages (from openpyxl) (1.1.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "! pip install openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mZUKZSW7SuKr",
    "outputId": "310ca31f-6c0a-4a41-8409-fc6f32f9c623"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (0.28.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (23.2)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.4)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0.1)\n",
      "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.2.0a0+81ea7a4)\n",
      "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.20.2)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.4.2)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (4.9.0)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.12)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.3)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2023.10.0)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (4.66.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2023.11.17)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mLooking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.39.3)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.12.25)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.2)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2023.10.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.9.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.11.17)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "! pip install -U accelerate\n",
    "! pip install -U transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "GqtaKhzhZxTj"
   },
   "outputs": [],
   "source": [
    "# Шаг 1: Подготовка данных\n",
    "#df = pd.read_excel('clean_dataset_3_credit_ratings_agencies_v2.0.xlsx')\n",
    "df = pd.read_excel('clean_train.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>pr_txt</th>\n",
       "      <th>Категория</th>\n",
       "      <th>Уровень рейтинга</th>\n",
       "      <th>pr_txt_cleaned</th>\n",
       "      <th>sentences_cleaned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>«Эксперт РА» подтвердил кредитный рейтинг комп...</td>\n",
       "      <td>BB</td>\n",
       "      <td>BB</td>\n",
       "      <td>«Эксперт РА» подтвердил кредитный рейтинг комп...</td>\n",
       "      <td>подтвердить кредитный рейтинг компания уровень...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>«Эксперт РА» присвоил кредитный рейтинг ПАО «Ф...</td>\n",
       "      <td>AAA</td>\n",
       "      <td>AAA</td>\n",
       "      <td>«Эксперт РА» присвоил кредитный рейтинг ПАО «Ф...</td>\n",
       "      <td>присвоить кредитный рейтинг уровень март рейти...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>«Эксперт РА» повысил кредитный рейтинг ОАО «МР...</td>\n",
       "      <td>AA</td>\n",
       "      <td>AA+</td>\n",
       "      <td>«Эксперт РА» повысил кредитный рейтинг ОАО «МР...</td>\n",
       "      <td>повысить кредитный рейтинг уровень март рейтин...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>«Эксперт РА» понизил кредитный рейтинг ПАО «М....</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>«Эксперт РА» понизил кредитный рейтинг ПАО «М....</td>\n",
       "      <td>понизить кредитный рейтинг уровень изменить пр...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>«Эксперт РА» повысил кредитный рейтинг компани...</td>\n",
       "      <td>BB</td>\n",
       "      <td>BB+</td>\n",
       "      <td>«Эксперт РА» повысил кредитный рейтинг компани...</td>\n",
       "      <td>повысить кредитный рейтинг компания уровень из...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1155</th>\n",
       "      <td>880</td>\n",
       "      <td>НКР присвоило группе \"РКС Девелопмент\" кредитн...</td>\n",
       "      <td>BBB</td>\n",
       "      <td>BBB-</td>\n",
       "      <td>Обоснование рейтингового действия Факторы, опр...</td>\n",
       "      <td>обоснование рейтинговый действие фактор опреде...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1156</th>\n",
       "      <td>908</td>\n",
       "      <td>НКР присвоило заводу КриалЭнергоСтрой кредитны...</td>\n",
       "      <td>BBB</td>\n",
       "      <td>BBB-</td>\n",
       "      <td>Обоснование рейтингового действия Факторы, опр...</td>\n",
       "      <td>обоснование рейтинговый действие фактор опреде...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1157</th>\n",
       "      <td>978</td>\n",
       "      <td>НКР присвоило группе «Самолет» кредитный рейти...</td>\n",
       "      <td>A</td>\n",
       "      <td>A-</td>\n",
       "      <td>Обоснование рейтингового действия Факторы, опр...</td>\n",
       "      <td>обоснование рейтинговый действие фактор опреде...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1158</th>\n",
       "      <td>1016</td>\n",
       "      <td>НКР присвоило «ПИК-Корпорации» кредитный рейти...</td>\n",
       "      <td>A</td>\n",
       "      <td>A+</td>\n",
       "      <td>Обоснование рейтингового действия Факторы, опр...</td>\n",
       "      <td>обоснование рейтинговый действие фактор опреде...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1159</th>\n",
       "      <td>1017</td>\n",
       "      <td>НКР присвоило группе компаний «ПИК» кредитный ...</td>\n",
       "      <td>A</td>\n",
       "      <td>A+</td>\n",
       "      <td>Обоснование рейтингового действия Факторы, опр...</td>\n",
       "      <td>обоснование рейтинговый действие фактор опреде...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1160 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Id                                             pr_txt Категория  \\\n",
       "0        2  «Эксперт РА» подтвердил кредитный рейтинг комп...        BB   \n",
       "1        4  «Эксперт РА» присвоил кредитный рейтинг ПАО «Ф...       AAA   \n",
       "2        7  «Эксперт РА» повысил кредитный рейтинг ОАО «МР...        AA   \n",
       "3        8  «Эксперт РА» понизил кредитный рейтинг ПАО «М....         A   \n",
       "4        9  «Эксперт РА» повысил кредитный рейтинг компани...        BB   \n",
       "...    ...                                                ...       ...   \n",
       "1155   880  НКР присвоило группе \"РКС Девелопмент\" кредитн...       BBB   \n",
       "1156   908  НКР присвоило заводу КриалЭнергоСтрой кредитны...       BBB   \n",
       "1157   978  НКР присвоило группе «Самолет» кредитный рейти...         A   \n",
       "1158  1016  НКР присвоило «ПИК-Корпорации» кредитный рейти...         A   \n",
       "1159  1017  НКР присвоило группе компаний «ПИК» кредитный ...         A   \n",
       "\n",
       "     Уровень рейтинга                                     pr_txt_cleaned  \\\n",
       "0                  BB  «Эксперт РА» подтвердил кредитный рейтинг комп...   \n",
       "1                 AAA  «Эксперт РА» присвоил кредитный рейтинг ПАО «Ф...   \n",
       "2                 AA+  «Эксперт РА» повысил кредитный рейтинг ОАО «МР...   \n",
       "3                   A  «Эксперт РА» понизил кредитный рейтинг ПАО «М....   \n",
       "4                 BB+  «Эксперт РА» повысил кредитный рейтинг компани...   \n",
       "...               ...                                                ...   \n",
       "1155             BBB-  Обоснование рейтингового действия Факторы, опр...   \n",
       "1156             BBB-  Обоснование рейтингового действия Факторы, опр...   \n",
       "1157               A-  Обоснование рейтингового действия Факторы, опр...   \n",
       "1158               A+  Обоснование рейтингового действия Факторы, опр...   \n",
       "1159               A+  Обоснование рейтингового действия Факторы, опр...   \n",
       "\n",
       "                                      sentences_cleaned  \n",
       "0     подтвердить кредитный рейтинг компания уровень...  \n",
       "1     присвоить кредитный рейтинг уровень март рейти...  \n",
       "2     повысить кредитный рейтинг уровень март рейтин...  \n",
       "3     понизить кредитный рейтинг уровень изменить пр...  \n",
       "4     повысить кредитный рейтинг компания уровень из...  \n",
       "...                                                 ...  \n",
       "1155  обоснование рейтинговый действие фактор опреде...  \n",
       "1156  обоснование рейтинговый действие фактор опреде...  \n",
       "1157  обоснование рейтинговый действие фактор опреде...  \n",
       "1158  обоснование рейтинговый действие фактор опреде...  \n",
       "1159  обоснование рейтинговый действие фактор опреде...  \n",
       "\n",
       "[1160 rows x 6 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "O9UEBw0VvNap",
    "outputId": "b7fee093-900b-4caa-b695-8829f472c017"
   },
   "outputs": [],
   "source": [
    "# Шаг 2: Токенизация текста\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"cointegrated/rubert-tiny2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TChyOBZVwAqk",
    "outputId": "870c51ae-5681-4749-8395-8e7750bc3763",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at cointegrated/rubert-tiny2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Шаг 3: Выбор модели (rubert-tiny2)\n",
    "from transformers import AutoModelForSequenceClassification#, BertConfig\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained('cointegrated/rubert-tiny2', num_labels=7)  # 7 классов уровня рейтинга"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Bzj939K2yUtu",
    "outputId": "3ce91810-f999-4d23-f946-7f88fde997a6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(83828, 312, padding_idx=0)\n",
       "      (position_embeddings): Embedding(2048, 312)\n",
       "      (token_type_embeddings): Embedding(2, 312)\n",
       "      (LayerNorm): LayerNorm((312,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-2): 3 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=312, out_features=312, bias=True)\n",
       "              (key): Linear(in_features=312, out_features=312, bias=True)\n",
       "              (value): Linear(in_features=312, out_features=312, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=312, out_features=312, bias=True)\n",
       "              (LayerNorm): LayerNorm((312,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=312, out_features=600, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=600, out_features=312, bias=True)\n",
       "            (LayerNorm): LayerNorm((312,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=312, out_features=312, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=312, out_features=7, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Шаг 4: Fine-tuning модели\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vjwSyeUCTM2C",
    "outputId": "40b8f75d-0a44-4e87-a85f-a1b1bfe99c85"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (2.16.1)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.13.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.26.4)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (14.0.1.dev0+gba5374836.d20240125)\n",
      "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets) (0.6)\n",
      "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.7)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n",
      "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.1)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.15)\n",
      "Requirement already satisfied: fsspec<=2023.10.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2023.10.0,>=2023.1.0->datasets) (2023.10.0)\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.9.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.19.4 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.20.2)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.2.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.4->datasets) (4.9.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2023.11.17)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.3.post1)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 66,
     "referenced_widgets": [
      "b07850732b5e43b2971e8e22411ac3f1",
      "8be92b5a3a364009b6af55286c91560b",
      "80207e4e50e2459984cf2beab036f66b",
      "37e17a11a1b74296a3ac0af683721623",
      "892587c0220b4b739ac6ac653483138f",
      "ae212bf556394b92aefa01a0c5274bc7",
      "acb512b19fee440880d3ec6864be4669",
      "2dbe750eb36f44afb572760c6361217e",
      "3dcbfc7b131c494facccd1467d5fde0f",
      "4fa69ef96038425196e202e85f65c419",
      "2aaeda6ccd094cc3996cce35823f695e"
     ]
    },
    "id": "DaIxewkxS96v",
    "outputId": "bffdb17a-67c5-47d1-f74c-e02bd78e8e9e"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd67817a1bb341aa9a23d6361a58a3d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset, load_metric, Dataset\n",
    "from transformers import AutoTokenizer, AutoModel, AutoModelForSequenceClassification, AdamW, get_scheduler\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "labels = le.fit_transform(df[\"Категория\"])\n",
    "df['labels'] = labels\n",
    "\n",
    "df = df[['pr_txt_cleaned', 'labels']]\n",
    "df.to_csv('CRA_train_1200.csv', index=False)\n",
    "full_dataset = load_dataset('csv', data_files='CRA_train_1200.csv')\n",
    "\n",
    "df.labels.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-ScuK3bII1TX",
    "outputId": "a39c1351-061b-417f-e598-4eed5a14f223"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['pr_txt_cleaned', 'labels'],\n",
       "        num_rows: 928\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['pr_txt_cleaned', 'labels'],\n",
       "        num_rows: 232\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_dataset = full_dataset['train'].train_test_split(test_size=0.2, seed = 17)\n",
    "full_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "2lAzRDhiHf2P"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from datasets import load_dataset # (dataset format for transformers lib) split train/test; feed to learning algorithm; fast fucntion apply - .map()\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import DataCollatorWithPadding #  to dynamically pad the sentences to the longest length in a batch during collation\n",
    "# import evaluate # loading metric F1\n",
    "from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer # TrainingArguments and Trainer are helpful instead of using verbose vanilla pytorh training workflow\n",
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 81,
     "referenced_widgets": [
      "b75811eaa63f40f0bb9a6e908db56001",
      "cf10dc85f4054f42afc998c4610cc88f",
      "0d3007d64cea4a50bcf32012fee8d17d",
      "afdfc15ad67b4088821d3b2d650b88ce",
      "8dcd632c9cab4753bdfc157e692e7fca",
      "75254c71403847e49dfed51646a30bdf",
      "a3ff77b4fb7c45e7af060e8871e9c1c5",
      "da4fac23ccbf4c289bc27ede999c2be9",
      "e2b1dd5ac52f4f1795f3e39bc66b998b",
      "a7d656e93e0c4fbda2ea8226996f7e22",
      "6605ce14652346a182a31dbc69d6db9e",
      "5bbe8d24867a4cef9c899bf9b4667665",
      "4bb90ce8f6794cdc80008b0b348332a3",
      "8189b7338ace4f379bdbe77dc48b8e7e",
      "28f57120d6d84cc2a421a3815fe3d6fe",
      "71952a9a8c944a1783d38195eae1550b",
      "a05b2fe8e9b54d92a2dcbde4d727e66a",
      "63a7e6d20dd04a21bdd73f0c5045bd82",
      "7b4abf3093c441b98e280cd14256fdd0",
      "4944065d9f1544a39718986e2e9fe33d",
      "abdebdbc5bad41088115f35fb2f1d5d6",
      "673cb2e6bd2c4676ba47d1c072f3675c"
     ]
    },
    "id": "DaZQz3TvGZeu",
    "outputId": "ca5ab0b4-04e2-4091-e8f6-c85213c9f30a"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d954b3a6ffc64eba9c0b02b2e595f824",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/928 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "851fcba69f7b44498c9d07d4fece96b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/232 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset_tokenized = full_dataset.map(lambda examples: tokenizer(examples[\"pr_txt_cleaned\"], truncation = True, max_length=2048, padding='max_length'), batched=True)\n",
    "\n",
    "dataset_tokenized.set_format(type='torch', device=device)\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer, max_length = 2048)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "PvV0dDEtIJOU"
   },
   "outputs": [],
   "source": [
    "from datasets import load_metric\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "COeWhUIdjbh_"
   },
   "outputs": [],
   "source": [
    "class MulticlassTrainer(Trainer):\n",
    "    # inheriting from Trainer class to override vanilla cross-entropy loss with weighted cross-enthropy loss\n",
    "    def __init__(self, weights, *args, **kwds):\n",
    "        super().__init__(*args, **kwds)\n",
    "        self.weights = weights\n",
    "    def compute_loss(self, model, inputs, return_outputs=False):\n",
    "        labels = inputs.get(\"labels\")\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.get('logits')\n",
    "        #loss = cross_entropy(logits.squeeze(), labels.squeeze(), torch.from_numpy(self.weights))\n",
    "        loss_fct = torch.nn.CrossEntropyLoss(weight=self.weights)\n",
    "        loss = loss_fct(logits.view(-1, self.model.config.num_labels), labels.view(-1))\n",
    "        #loss = log_loss(labels.squeeze(), logits.squeeze(), sample_weight = self.weights)\n",
    "        return (loss, outputs) if return_outputs else loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cXFinPXgIP5w",
    "outputId": "5ef05b95-599a-4f9e-f3db-2492c9e1164f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_14351/2817711593.py:1: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library 🤗 Evaluate: https://huggingface.co/docs/evaluate\n",
      "  f1_metric = load_metric(\"f1\", trust_remote_code=True)\n"
     ]
    }
   ],
   "source": [
    "f1_metric = load_metric(\"f1\", trust_remote_code=True)\n",
    "def compute_metrics(eval_pred):\n",
    "    # using macro f1\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return f1_metric.compute(predictions=predictions, references=labels, average=\"macro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rmT-5W2kIThm",
    "outputId": "1c5081be-3d25-4e09-e81c-cbf759f4820f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/accelerate/accelerator.py:432: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    #output_dir=\"./drive/MyDrive/ML/Models/female_clothing_class\", # checkpoints are saved here\n",
    "    output_dir = \"./out\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs = 60,\n",
    "    warmup_steps=500,  # Количество шагов разогрева\n",
    "    weight_decay=0.01,\n",
    "    logging_dir=\"./runs\",  # Каталог для логов TensorBoard\n",
    "    logging_steps=50,  # Логирование каждые 400 шагов\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=50,\n",
    "    save_strategy=\"steps\",\n",
    "    save_steps = 1500,\n",
    "    save_total_limit = 10, # max number of model checkpoints to safe\n",
    "    load_best_model_at_end=True, # automatically loads the best model (save_steps and eval_steps must be multiples oh each other)\n",
    "    metric_for_best_model=\"f1\",  # Метрика для выбора лучшей модели\n",
    "    #report_to='tensorboard', # it's also possible to report to weights & biases or other\n",
    "    greater_is_better=True  # Указывает, что большее значение F1 лучше\n",
    ")\n",
    "\n",
    "# weights for unbalanced classes\n",
    "weights = compute_class_weight(class_weight=\"balanced\", classes=np.unique(dataset_tokenized[\"train\"][\"labels\"].cpu().numpy()), y=dataset_tokenized[\"train\"][\"labels\"].cpu().numpy())\n",
    "WEIGHTS = torch.from_numpy(weights).float().to(device)\n",
    "\n",
    "trainer = MulticlassTrainer(\n",
    "    WEIGHTS,\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=dataset_tokenized[\"train\"],\n",
    "    eval_dataset=dataset_tokenized[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    "    #callbacks = [tb]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PlCCgyMKJGhc",
    "outputId": "d48a88a4-74ec-40f1-9599-f952c65823b7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_args.device # check the current device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total CUDA memory: 79.169677734375\n",
      "Allocated CUDA memory: 0.10903215408325195\n",
      "Cached CUDA memory: 0.126953125\n"
     ]
    }
   ],
   "source": [
    "def print_cuda_memory():\n",
    "    print(\"Total CUDA memory:\", torch.cuda.get_device_properties(0).total_memory/(2**30))\n",
    "    print(\"Allocated CUDA memory:\", torch.cuda.memory_allocated()/(2**30))\n",
    "    print(\"Cached CUDA memory:\", torch.cuda.memory_reserved()/(2**30))\n",
    "\n",
    "print_cuda_memory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 515
    },
    "id": "ihUkKpajJJJ8",
    "outputId": "6ae5a17b-3db2-4c85-a68c-d6ab6d9f5f82"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2706: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6960' max='6960' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6960/6960 15:02, Epoch 60/60]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.948400</td>\n",
       "      <td>1.946969</td>\n",
       "      <td>0.051673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.941200</td>\n",
       "      <td>1.935951</td>\n",
       "      <td>0.074785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1.924800</td>\n",
       "      <td>1.915184</td>\n",
       "      <td>0.078000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1.910500</td>\n",
       "      <td>1.892432</td>\n",
       "      <td>0.096755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>1.882400</td>\n",
       "      <td>1.866293</td>\n",
       "      <td>0.093800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>1.859500</td>\n",
       "      <td>1.849899</td>\n",
       "      <td>0.079631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>1.873400</td>\n",
       "      <td>1.832311</td>\n",
       "      <td>0.157778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>1.870300</td>\n",
       "      <td>1.810745</td>\n",
       "      <td>0.142780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>1.806600</td>\n",
       "      <td>1.793448</td>\n",
       "      <td>0.175713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>1.786400</td>\n",
       "      <td>1.751880</td>\n",
       "      <td>0.213680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>1.724100</td>\n",
       "      <td>1.686718</td>\n",
       "      <td>0.322488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>1.661900</td>\n",
       "      <td>1.616625</td>\n",
       "      <td>0.279644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>1.571700</td>\n",
       "      <td>1.553621</td>\n",
       "      <td>0.385868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>1.480500</td>\n",
       "      <td>1.498772</td>\n",
       "      <td>0.281670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>1.395900</td>\n",
       "      <td>1.404055</td>\n",
       "      <td>0.349685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>1.355900</td>\n",
       "      <td>1.423914</td>\n",
       "      <td>0.318739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>1.328800</td>\n",
       "      <td>1.326079</td>\n",
       "      <td>0.358516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>1.233800</td>\n",
       "      <td>1.291067</td>\n",
       "      <td>0.444199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>1.170100</td>\n",
       "      <td>1.264938</td>\n",
       "      <td>0.368059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>1.136300</td>\n",
       "      <td>1.231627</td>\n",
       "      <td>0.420424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1050</td>\n",
       "      <td>1.099700</td>\n",
       "      <td>1.182675</td>\n",
       "      <td>0.425793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>1.054200</td>\n",
       "      <td>1.207674</td>\n",
       "      <td>0.427276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1150</td>\n",
       "      <td>0.950700</td>\n",
       "      <td>1.123846</td>\n",
       "      <td>0.437221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.924600</td>\n",
       "      <td>1.135723</td>\n",
       "      <td>0.464675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1250</td>\n",
       "      <td>0.906600</td>\n",
       "      <td>1.068061</td>\n",
       "      <td>0.504998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>0.859100</td>\n",
       "      <td>1.046004</td>\n",
       "      <td>0.539024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1350</td>\n",
       "      <td>0.784400</td>\n",
       "      <td>1.015114</td>\n",
       "      <td>0.586193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.769100</td>\n",
       "      <td>1.011222</td>\n",
       "      <td>0.551180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1450</td>\n",
       "      <td>0.706700</td>\n",
       "      <td>0.976996</td>\n",
       "      <td>0.659255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.673500</td>\n",
       "      <td>0.953387</td>\n",
       "      <td>0.603239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1550</td>\n",
       "      <td>0.614000</td>\n",
       "      <td>0.931230</td>\n",
       "      <td>0.562281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.611500</td>\n",
       "      <td>1.017564</td>\n",
       "      <td>0.607628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1650</td>\n",
       "      <td>0.559200</td>\n",
       "      <td>0.928956</td>\n",
       "      <td>0.629998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>0.506000</td>\n",
       "      <td>0.904721</td>\n",
       "      <td>0.657823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1750</td>\n",
       "      <td>0.522000</td>\n",
       "      <td>0.885296</td>\n",
       "      <td>0.644187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.460200</td>\n",
       "      <td>0.880254</td>\n",
       "      <td>0.661713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1850</td>\n",
       "      <td>0.425600</td>\n",
       "      <td>0.868017</td>\n",
       "      <td>0.665853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1900</td>\n",
       "      <td>0.401900</td>\n",
       "      <td>0.866018</td>\n",
       "      <td>0.657533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1950</td>\n",
       "      <td>0.376000</td>\n",
       "      <td>0.882071</td>\n",
       "      <td>0.653802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.345200</td>\n",
       "      <td>0.877198</td>\n",
       "      <td>0.660070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2050</td>\n",
       "      <td>0.316300</td>\n",
       "      <td>0.852994</td>\n",
       "      <td>0.653613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2100</td>\n",
       "      <td>0.309600</td>\n",
       "      <td>0.935668</td>\n",
       "      <td>0.657766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2150</td>\n",
       "      <td>0.270100</td>\n",
       "      <td>0.858940</td>\n",
       "      <td>0.653526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>0.259000</td>\n",
       "      <td>0.942772</td>\n",
       "      <td>0.673681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2250</td>\n",
       "      <td>0.241000</td>\n",
       "      <td>0.876243</td>\n",
       "      <td>0.665101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2300</td>\n",
       "      <td>0.196800</td>\n",
       "      <td>0.895084</td>\n",
       "      <td>0.679407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2350</td>\n",
       "      <td>0.203900</td>\n",
       "      <td>0.861790</td>\n",
       "      <td>0.678582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>0.168400</td>\n",
       "      <td>0.915333</td>\n",
       "      <td>0.668685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2450</td>\n",
       "      <td>0.171800</td>\n",
       "      <td>0.911529</td>\n",
       "      <td>0.685588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.153900</td>\n",
       "      <td>0.872140</td>\n",
       "      <td>0.694350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2550</td>\n",
       "      <td>0.134800</td>\n",
       "      <td>0.918291</td>\n",
       "      <td>0.635329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>0.133100</td>\n",
       "      <td>0.941641</td>\n",
       "      <td>0.682123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2650</td>\n",
       "      <td>0.115100</td>\n",
       "      <td>0.896145</td>\n",
       "      <td>0.679693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2700</td>\n",
       "      <td>0.103800</td>\n",
       "      <td>0.945246</td>\n",
       "      <td>0.687492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2750</td>\n",
       "      <td>0.091300</td>\n",
       "      <td>0.956682</td>\n",
       "      <td>0.674196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>0.082500</td>\n",
       "      <td>0.995748</td>\n",
       "      <td>0.656739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2850</td>\n",
       "      <td>0.074200</td>\n",
       "      <td>0.964499</td>\n",
       "      <td>0.669742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2900</td>\n",
       "      <td>0.073700</td>\n",
       "      <td>0.944394</td>\n",
       "      <td>0.680644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2950</td>\n",
       "      <td>0.058900</td>\n",
       "      <td>0.999110</td>\n",
       "      <td>0.681862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.056600</td>\n",
       "      <td>1.011241</td>\n",
       "      <td>0.681212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3050</td>\n",
       "      <td>0.052200</td>\n",
       "      <td>0.992745</td>\n",
       "      <td>0.725091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3100</td>\n",
       "      <td>0.042600</td>\n",
       "      <td>0.996936</td>\n",
       "      <td>0.678460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3150</td>\n",
       "      <td>0.046700</td>\n",
       "      <td>1.069615</td>\n",
       "      <td>0.669747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3200</td>\n",
       "      <td>0.037200</td>\n",
       "      <td>1.036344</td>\n",
       "      <td>0.694423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3250</td>\n",
       "      <td>0.040700</td>\n",
       "      <td>1.052615</td>\n",
       "      <td>0.706329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3300</td>\n",
       "      <td>0.037100</td>\n",
       "      <td>1.094526</td>\n",
       "      <td>0.700891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3350</td>\n",
       "      <td>0.026100</td>\n",
       "      <td>1.086242</td>\n",
       "      <td>0.700351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3400</td>\n",
       "      <td>0.030500</td>\n",
       "      <td>1.062393</td>\n",
       "      <td>0.696970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3450</td>\n",
       "      <td>0.022400</td>\n",
       "      <td>1.072438</td>\n",
       "      <td>0.724895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>0.019700</td>\n",
       "      <td>1.085453</td>\n",
       "      <td>0.697694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3550</td>\n",
       "      <td>0.019700</td>\n",
       "      <td>1.215194</td>\n",
       "      <td>0.677555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3600</td>\n",
       "      <td>0.017700</td>\n",
       "      <td>1.120842</td>\n",
       "      <td>0.708158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3650</td>\n",
       "      <td>0.014800</td>\n",
       "      <td>1.132747</td>\n",
       "      <td>0.713051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3700</td>\n",
       "      <td>0.014700</td>\n",
       "      <td>1.103480</td>\n",
       "      <td>0.711894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3750</td>\n",
       "      <td>0.014000</td>\n",
       "      <td>1.174629</td>\n",
       "      <td>0.710511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3800</td>\n",
       "      <td>0.012200</td>\n",
       "      <td>1.117719</td>\n",
       "      <td>0.714692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3850</td>\n",
       "      <td>0.012300</td>\n",
       "      <td>1.141623</td>\n",
       "      <td>0.698822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3900</td>\n",
       "      <td>0.010400</td>\n",
       "      <td>1.186997</td>\n",
       "      <td>0.718414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3950</td>\n",
       "      <td>0.009200</td>\n",
       "      <td>1.253987</td>\n",
       "      <td>0.706258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.009200</td>\n",
       "      <td>1.223882</td>\n",
       "      <td>0.706458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4050</td>\n",
       "      <td>0.008900</td>\n",
       "      <td>1.186761</td>\n",
       "      <td>0.711701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4100</td>\n",
       "      <td>0.008100</td>\n",
       "      <td>1.160434</td>\n",
       "      <td>0.716710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4150</td>\n",
       "      <td>0.008100</td>\n",
       "      <td>1.191209</td>\n",
       "      <td>0.720243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4200</td>\n",
       "      <td>0.007700</td>\n",
       "      <td>1.281317</td>\n",
       "      <td>0.710868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4250</td>\n",
       "      <td>0.007600</td>\n",
       "      <td>1.229551</td>\n",
       "      <td>0.706835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4300</td>\n",
       "      <td>0.007700</td>\n",
       "      <td>1.302972</td>\n",
       "      <td>0.709313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4350</td>\n",
       "      <td>0.007400</td>\n",
       "      <td>1.232821</td>\n",
       "      <td>0.711216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4400</td>\n",
       "      <td>0.006700</td>\n",
       "      <td>1.279267</td>\n",
       "      <td>0.708927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4450</td>\n",
       "      <td>0.006500</td>\n",
       "      <td>1.280155</td>\n",
       "      <td>0.723229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>0.018400</td>\n",
       "      <td>1.232321</td>\n",
       "      <td>0.722507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4550</td>\n",
       "      <td>0.005700</td>\n",
       "      <td>1.268161</td>\n",
       "      <td>0.717509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4600</td>\n",
       "      <td>0.005500</td>\n",
       "      <td>1.299464</td>\n",
       "      <td>0.730404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4650</td>\n",
       "      <td>0.005100</td>\n",
       "      <td>1.275996</td>\n",
       "      <td>0.716426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4700</td>\n",
       "      <td>0.005100</td>\n",
       "      <td>1.268164</td>\n",
       "      <td>0.715390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4750</td>\n",
       "      <td>0.004900</td>\n",
       "      <td>1.293277</td>\n",
       "      <td>0.703429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4800</td>\n",
       "      <td>0.005000</td>\n",
       "      <td>1.232712</td>\n",
       "      <td>0.727032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4850</td>\n",
       "      <td>0.004700</td>\n",
       "      <td>1.263775</td>\n",
       "      <td>0.724201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4900</td>\n",
       "      <td>0.004900</td>\n",
       "      <td>1.271680</td>\n",
       "      <td>0.722038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4950</td>\n",
       "      <td>0.004300</td>\n",
       "      <td>1.256532</td>\n",
       "      <td>0.731660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.004200</td>\n",
       "      <td>1.304229</td>\n",
       "      <td>0.725764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5050</td>\n",
       "      <td>0.004000</td>\n",
       "      <td>1.319675</td>\n",
       "      <td>0.721165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5100</td>\n",
       "      <td>0.004300</td>\n",
       "      <td>1.302408</td>\n",
       "      <td>0.729957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5150</td>\n",
       "      <td>0.003900</td>\n",
       "      <td>1.344887</td>\n",
       "      <td>0.715207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5200</td>\n",
       "      <td>0.003700</td>\n",
       "      <td>1.321840</td>\n",
       "      <td>0.728231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5250</td>\n",
       "      <td>0.003700</td>\n",
       "      <td>1.284096</td>\n",
       "      <td>0.740415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5300</td>\n",
       "      <td>0.003700</td>\n",
       "      <td>1.298148</td>\n",
       "      <td>0.734966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5350</td>\n",
       "      <td>0.003500</td>\n",
       "      <td>1.343130</td>\n",
       "      <td>0.709201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5400</td>\n",
       "      <td>0.003900</td>\n",
       "      <td>1.288743</td>\n",
       "      <td>0.727421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5450</td>\n",
       "      <td>0.003400</td>\n",
       "      <td>1.336564</td>\n",
       "      <td>0.733095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5500</td>\n",
       "      <td>0.003500</td>\n",
       "      <td>1.277411</td>\n",
       "      <td>0.730837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5550</td>\n",
       "      <td>0.003300</td>\n",
       "      <td>1.321827</td>\n",
       "      <td>0.727460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5600</td>\n",
       "      <td>0.003100</td>\n",
       "      <td>1.392890</td>\n",
       "      <td>0.724998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5650</td>\n",
       "      <td>0.003200</td>\n",
       "      <td>1.318539</td>\n",
       "      <td>0.728589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5700</td>\n",
       "      <td>0.003400</td>\n",
       "      <td>1.305366</td>\n",
       "      <td>0.724192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5750</td>\n",
       "      <td>0.003000</td>\n",
       "      <td>1.340555</td>\n",
       "      <td>0.730477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5800</td>\n",
       "      <td>0.004200</td>\n",
       "      <td>1.331718</td>\n",
       "      <td>0.704983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5850</td>\n",
       "      <td>0.003100</td>\n",
       "      <td>1.356759</td>\n",
       "      <td>0.728589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5900</td>\n",
       "      <td>0.002900</td>\n",
       "      <td>1.383880</td>\n",
       "      <td>0.716287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5950</td>\n",
       "      <td>0.002900</td>\n",
       "      <td>1.323204</td>\n",
       "      <td>0.738164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.003100</td>\n",
       "      <td>1.315637</td>\n",
       "      <td>0.727577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6050</td>\n",
       "      <td>0.002500</td>\n",
       "      <td>1.332646</td>\n",
       "      <td>0.724192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6100</td>\n",
       "      <td>0.002900</td>\n",
       "      <td>1.393921</td>\n",
       "      <td>0.713090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6150</td>\n",
       "      <td>0.003000</td>\n",
       "      <td>1.386978</td>\n",
       "      <td>0.715002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6200</td>\n",
       "      <td>0.002500</td>\n",
       "      <td>1.361602</td>\n",
       "      <td>0.726592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6250</td>\n",
       "      <td>0.002800</td>\n",
       "      <td>1.393605</td>\n",
       "      <td>0.722237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6300</td>\n",
       "      <td>0.002700</td>\n",
       "      <td>1.364102</td>\n",
       "      <td>0.733899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6350</td>\n",
       "      <td>0.002600</td>\n",
       "      <td>1.340494</td>\n",
       "      <td>0.729712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6400</td>\n",
       "      <td>0.002700</td>\n",
       "      <td>1.344029</td>\n",
       "      <td>0.732807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6450</td>\n",
       "      <td>0.002500</td>\n",
       "      <td>1.348989</td>\n",
       "      <td>0.732850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6500</td>\n",
       "      <td>0.002500</td>\n",
       "      <td>1.370306</td>\n",
       "      <td>0.732165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6550</td>\n",
       "      <td>0.002500</td>\n",
       "      <td>1.363428</td>\n",
       "      <td>0.731880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6600</td>\n",
       "      <td>0.002500</td>\n",
       "      <td>1.357179</td>\n",
       "      <td>0.728850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6650</td>\n",
       "      <td>0.002600</td>\n",
       "      <td>1.353553</td>\n",
       "      <td>0.731880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6700</td>\n",
       "      <td>0.002500</td>\n",
       "      <td>1.348978</td>\n",
       "      <td>0.726975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6750</td>\n",
       "      <td>0.002700</td>\n",
       "      <td>1.338210</td>\n",
       "      <td>0.736502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6800</td>\n",
       "      <td>0.002600</td>\n",
       "      <td>1.369112</td>\n",
       "      <td>0.728850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6850</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>1.375171</td>\n",
       "      <td>0.728850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6900</td>\n",
       "      <td>0.002500</td>\n",
       "      <td>1.374041</td>\n",
       "      <td>0.728850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6950</td>\n",
       "      <td>0.002300</td>\n",
       "      <td>1.375900</td>\n",
       "      <td>0.728850</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2706: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2706: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2706: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2706: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2706: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2706: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2706: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2706: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2706: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2706: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2706: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2706: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2706: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2706: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2706: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2706: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2706: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2706: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2706: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2706: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2706: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2706: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2706: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2706: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2706: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2706: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2706: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2706: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2706: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2706: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2706: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2706: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2706: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2706: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2706: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2706: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2706: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2706: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2706: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2706: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2706: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2706: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2706: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2706: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2706: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2706: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2706: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2706: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2706: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2706: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2706: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2706: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2706: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2706: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2706: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2706: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2706: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2706: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2706: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2706: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2706: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2706: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2706: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2706: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2706: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2706: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2706: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2706: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2706: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2706: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2706: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2706: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2706: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2706: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2706: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2706: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2706: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2706: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2706: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2706: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2706: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2706: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2706: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2706: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2706: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2706: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2706: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2706: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2706: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2706: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2706: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2706: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2706: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2706: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2706: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2706: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2706: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2706: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2706: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2706: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2706: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2706: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2706: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2706: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2706: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2706: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2706: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2706: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2706: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2706: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2706: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2706: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2706: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2706: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2706: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2706: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2706: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2706: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2706: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2706: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2706: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2706: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2706: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2706: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2706: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2706: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2706: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2706: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2706: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2706: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2706: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2706: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2706: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2706: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2706: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2706: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2706: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2706: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2706: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=6960, training_loss=0.36187212182390877, metrics={'train_runtime': 902.7102, 'train_samples_per_second': 61.681, 'train_steps_per_second': 7.71, 'total_flos': 1643454144184320.0, 'train_loss': 0.36187212182390877, 'epoch': 60.0})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train(resume_from_checkpoint=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_test = pd.read_excel('clean_test.xlsx')\n",
    "df_test = pd.read_excel('CRA_validation_110_answers.xlsx')\n",
    "#X_test = df_test['pr_txt_cleaned']  # Входные данные - описание компании\n",
    "#y_test = df_test['Категория']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "byxbxgPLMw34"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7d4cc9369144b9fa7a65e4bcdaa2075",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset, load_metric, Dataset\n",
    "from transformers import AutoTokenizer, AutoModel, AutoModelForSequenceClassification, AdamW, get_scheduler\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "labels = le.fit_transform(df_test[\"Категория\"])\n",
    "df_test['labels'] = labels\n",
    "\n",
    "df_test = df_test[['pr_txt', 'labels']]\n",
    "df_test.to_csv('CRA_test_110_answers.csv', index=False)\n",
    "test_dataset = load_dataset('csv', data_files='CRA_test_110_answers.csv')\n",
    "# Фильтрация записей, в которых текстовые поля или метки не являются None\n",
    "#full_dataset = full_dataset.filter(lambda example: example['Review Text'] is not None and example['Recommended IND'] is not None)\n",
    "\n",
    "df_test.labels.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e16624ea739547d1b215986d267d9031",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/110 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_dataset_tokenized = test_dataset.map(lambda examples: tokenizer(examples[\"pr_txt\"], truncation = True, max_length=2048, padding='max_length'), batched=True)\n",
    "# automatically truncate long sentences to be no longer than DistilBERT’s maximum input length\n",
    "\n",
    "test_dataset_tokenized.set_format(type='torch', device=device)\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer, max_length = 2048)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2706: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "preds = trainer.predict(test_dataset_tokenized['train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PredictionOutput(predictions=array([[-2.12807202e+00, -3.90787911e+00, -5.44260144e-01,\n",
       "        -4.85247932e-02,  6.71468115e+00, -9.43976760e-01,\n",
       "        -9.92004871e-01],\n",
       "       [ 5.63018918e-01,  6.64142084e+00, -1.81935179e+00,\n",
       "        -1.91029751e+00, -2.99364018e+00,  1.15416765e+00,\n",
       "        -7.17695951e-01],\n",
       "       [-1.87608635e+00, -4.21275616e+00, -1.17727768e+00,\n",
       "        -9.75859523e-01,  6.92421532e+00,  5.39640546e-01,\n",
       "        -1.30190873e+00],\n",
       "       [ 6.38750553e+00, -1.65200698e+00, -3.09478998e+00,\n",
       "        -9.89487886e-01,  1.52845159e-01, -5.23266017e-01,\n",
       "        -1.39624262e+00],\n",
       "       [ 4.16835690e+00, -3.29812169e+00, -2.53669095e+00,\n",
       "        -3.67311716e-01,  2.70940900e+00, -6.74333096e-01,\n",
       "        -1.74616790e+00],\n",
       "       [ 1.49865985e+00, -4.06721687e+00, -3.61190009e+00,\n",
       "        -1.37240851e+00,  3.90869379e+00,  2.75568247e+00,\n",
       "        -1.22052324e+00],\n",
       "       [ 8.65659595e-01,  7.44091320e+00, -7.00417042e-01,\n",
       "        -1.88672578e+00, -3.80693579e+00,  3.35606724e-01,\n",
       "        -8.59155357e-01],\n",
       "       [ 7.16958761e+00, -1.35680532e+00, -2.02948260e+00,\n",
       "        -1.24253476e+00, -1.04573679e+00, -9.11866486e-01,\n",
       "        -1.19547701e+00],\n",
       "       [-9.81354177e-01,  5.40336311e-01,  7.49807596e+00,\n",
       "        -5.76259375e-01, -9.88641322e-01, -3.48415589e+00,\n",
       "        -3.77265424e-01],\n",
       "       [-1.22172153e+00, -5.52443862e-01, -3.42660570e+00,\n",
       "        -2.30767393e+00, -9.88342315e-02,  7.15525055e+00,\n",
       "        -4.88492250e-01],\n",
       "       [ 2.73463935e-01, -2.48111629e+00, -4.02096844e+00,\n",
       "        -2.21592712e+00,  1.73980653e+00,  6.34609175e+00,\n",
       "        -1.23271644e+00],\n",
       "       [ 7.14078331e+00, -1.16846859e+00, -1.70882452e+00,\n",
       "        -1.19605398e+00, -1.18919265e+00, -1.21325898e+00,\n",
       "        -1.18086898e+00],\n",
       "       [ 5.66573095e+00, -2.76385093e+00, -3.34114933e+00,\n",
       "        -1.50389910e-01,  9.75966871e-01, -7.04308689e-01,\n",
       "        -1.09230840e+00],\n",
       "       [ 6.95774841e+00, -8.16547871e-01, -2.88564968e+00,\n",
       "        -1.06853116e+00, -7.04651415e-01, -8.70616198e-01,\n",
       "        -1.47255790e+00],\n",
       "       [-1.60479414e+00, -2.36186910e+00, -3.26259327e+00,\n",
       "        -1.99760377e+00,  2.79284120e+00,  5.59792233e+00,\n",
       "        -6.24692142e-01],\n",
       "       [ 6.22098970e+00, -1.75817943e+00, -3.06721663e+00,\n",
       "        -2.10079622e+00, -5.12956738e-01,  1.57989931e+00,\n",
       "        -1.50564969e+00],\n",
       "       [ 7.00024891e+00, -1.07808936e+00, -1.38325822e+00,\n",
       "        -1.03904366e+00, -1.11033118e+00, -1.31733072e+00,\n",
       "        -1.63549089e+00],\n",
       "       [ 6.94852495e+00, -1.11223304e+00, -2.72025728e+00,\n",
       "        -1.16867948e+00, -3.36937845e-01, -8.96691799e-01,\n",
       "        -1.63223803e+00],\n",
       "       [ 6.26181269e+00, -1.78468502e+00, -2.10836411e+00,\n",
       "         2.64706016e-02, -3.89034957e-01, -1.89616489e+00,\n",
       "        -8.80768716e-01],\n",
       "       [ 6.29797029e+00, -2.37945127e+00, -2.80134511e+00,\n",
       "        -9.82203066e-01,  3.39138091e-01, -3.56409729e-01,\n",
       "        -1.28624892e+00],\n",
       "       [-2.14937901e+00, -4.29946280e+00, -1.37150705e+00,\n",
       "        -7.07908154e-01,  6.95976734e+00,  6.60247087e-01,\n",
       "        -1.17283404e+00],\n",
       "       [-2.84130597e+00,  1.10950387e+00,  7.46742964e+00,\n",
       "        -6.55649126e-01, -4.55709904e-01, -2.84410024e+00,\n",
       "        -1.05770910e-03],\n",
       "       [-1.14270067e+00, -1.25176072e+00, -1.18582845e+00,\n",
       "         6.41860485e+00, -6.88414097e-01, -2.06208110e+00,\n",
       "        -5.98805487e-01],\n",
       "       [ 5.37207985e+00, -2.42040038e+00, -3.27683401e+00,\n",
       "        -7.25884557e-01,  9.22991395e-01, -5.04850924e-01,\n",
       "        -7.77678967e-01],\n",
       "       [ 4.94868231e+00, -2.14868808e+00, -2.63373899e+00,\n",
       "         7.94578418e-02,  1.59773791e+00, -1.71053672e+00,\n",
       "        -1.46579266e+00],\n",
       "       [-1.19388628e+00, -1.72720861e+00, -1.09391201e+00,\n",
       "         6.37019920e+00,  2.02961087e-01, -2.56066298e+00,\n",
       "        -7.73757994e-01],\n",
       "       [-1.96593070e+00,  3.18165980e-02,  7.63296986e+00,\n",
       "        -5.08124113e-01, -3.83746058e-01, -2.84755254e+00,\n",
       "        -3.59171808e-01],\n",
       "       [-8.19905639e-01, -1.67267954e+00, -1.14587986e+00,\n",
       "         6.41256809e+00, -6.77521825e-01, -2.08544326e+00,\n",
       "        -6.42529488e-01],\n",
       "       [-5.56521475e-01, -4.39048672e+00, -1.85336959e+00,\n",
       "         5.30802786e-01,  6.19163227e+00, -9.44230497e-01,\n",
       "        -1.16052234e+00],\n",
       "       [ 7.02727222e+00, -7.90164709e-01, -3.33185673e+00,\n",
       "        -2.01481080e+00, -1.16580379e+00,  6.73853040e-01,\n",
       "        -1.23920465e+00],\n",
       "       [-2.15095803e-01,  7.54979229e+00,  9.02211443e-02,\n",
       "        -1.60077620e+00, -3.37425065e+00, -3.95626158e-01,\n",
       "        -7.41927087e-01],\n",
       "       [ 4.81817865e+00, -1.99570549e+00, -1.74499035e+00,\n",
       "        -6.83623731e-01,  7.11916685e-01, -5.64722300e-01,\n",
       "        -1.66968942e+00],\n",
       "       [-1.66626906e+00, -3.94046044e+00, -1.44323146e+00,\n",
       "        -1.30615234e+00,  6.72211981e+00,  9.94641960e-01,\n",
       "        -1.45607340e+00],\n",
       "       [ 7.65131354e-01,  6.41443014e+00, -1.60378277e+00,\n",
       "        -1.90776861e+00, -2.59958434e+00,  3.54632080e-01,\n",
       "        -5.12795508e-01],\n",
       "       [ 6.22403288e+00, -1.25897563e+00, -2.04163432e+00,\n",
       "         4.38198149e-01, -8.56997669e-01, -1.76195192e+00,\n",
       "        -1.55752838e+00],\n",
       "       [-1.44727826e+00, -1.71116221e+00, -3.30923033e+00,\n",
       "        -2.45555305e+00,  2.25614858e+00,  6.07615137e+00,\n",
       "        -8.27986062e-01],\n",
       "       [ 6.98366404e+00, -1.37862360e+00, -2.44840932e+00,\n",
       "        -1.09999216e+00, -7.21290529e-01, -8.86772811e-01,\n",
       "        -1.18195200e+00],\n",
       "       [-2.57671547e+00,  1.09377873e+00,  7.56552982e+00,\n",
       "        -6.80364847e-01, -4.98454332e-01, -2.91020060e+00,\n",
       "        -2.35751525e-01],\n",
       "       [-1.46005857e+00, -4.12900686e-01, -3.66461873e+00,\n",
       "        -2.46661782e+00,  8.53673995e-01,  6.80976629e+00,\n",
       "        -7.66221464e-01],\n",
       "       [-1.41423762e+00,  1.96867800e+00,  7.25017595e+00,\n",
       "        -7.86407709e-01, -1.38650560e+00, -3.73715878e+00,\n",
       "        -3.40726227e-02],\n",
       "       [-3.93704891e-01,  7.52833748e+00, -5.23872674e-01,\n",
       "        -1.38977730e+00, -3.59356070e+00,  2.67548293e-01,\n",
       "        -5.99218071e-01],\n",
       "       [ 7.05666065e+00, -1.65968668e+00, -2.54627013e+00,\n",
       "        -1.46362162e+00, -8.66319537e-01, -1.67508319e-01,\n",
       "        -1.14939702e+00],\n",
       "       [ 6.91368437e+00, -6.01850271e-01, -2.91564441e+00,\n",
       "        -2.52571797e+00, -9.56065595e-01,  8.46685290e-01,\n",
       "        -1.63313937e+00],\n",
       "       [-2.25618690e-01, -5.13249826e+00, -2.49158430e+00,\n",
       "        -7.47764587e-01,  6.04859257e+00,  1.36550653e+00,\n",
       "        -1.22021890e+00],\n",
       "       [ 6.45446491e+00, -1.44909191e+00, -3.42585492e+00,\n",
       "        -1.82337058e+00, -6.63235486e-01,  1.30998814e+00,\n",
       "        -1.49700201e+00],\n",
       "       [-1.49851942e+00, -2.74574065e+00, -3.11715198e+00,\n",
       "        -2.19690180e+00,  3.76877880e+00,  4.93213129e+00,\n",
       "        -7.71680415e-01],\n",
       "       [ 5.88950348e+00,  9.64062154e-01, -1.96719632e-01,\n",
       "        -9.07418728e-01, -1.90220761e+00, -2.17439461e+00,\n",
       "        -1.61129463e+00],\n",
       "       [ 4.97582483e+00, -3.21123457e+00, -2.08603382e+00,\n",
       "        -9.12101805e-01,  2.38393044e+00, -1.35851550e+00,\n",
       "        -1.27468646e+00],\n",
       "       [ 6.70378590e+00, -1.67301559e+00, -3.08142877e+00,\n",
       "        -1.27580249e+00, -4.61596549e-01, -1.02581652e-02,\n",
       "        -1.16790700e+00],\n",
       "       [-9.14610803e-01, -1.27610695e+00, -3.42332816e+00,\n",
       "        -2.53327847e+00,  6.13179445e-01,  7.03981876e+00,\n",
       "        -6.45986021e-01],\n",
       "       [-1.30907357e+00, -1.68231809e+00, -3.23403192e+00,\n",
       "        -2.32022643e+00,  1.62277448e+00,  6.47484970e+00,\n",
       "        -8.21612120e-01],\n",
       "       [-2.31742716e+00,  1.94425896e-01,  7.66714287e+00,\n",
       "        -5.95614672e-01, -2.55897611e-01, -2.87714243e+00,\n",
       "        -1.72611043e-01],\n",
       "       [-1.01486897e+00, -2.42962450e-01, -3.59954834e+00,\n",
       "        -2.18069410e+00, -2.43161306e-01,  7.11633539e+00,\n",
       "        -7.99926817e-01],\n",
       "       [-1.72508657e+00, -3.19531536e+00, -2.15141249e+00,\n",
       "        -2.15489244e+00,  4.82855844e+00,  3.86888433e+00,\n",
       "        -1.28154123e+00],\n",
       "       [ 6.58517075e+00, -1.41862643e+00, -2.04963326e+00,\n",
       "        -3.87950629e-01, -6.52132750e-01, -1.49356198e+00,\n",
       "        -1.33224475e+00],\n",
       "       [-1.15013015e+00, -2.15301943e+00, -3.34093404e+00,\n",
       "        -2.34247041e+00,  1.91166711e+00,  6.44536638e+00,\n",
       "        -7.23972559e-01],\n",
       "       [-1.84614134e+00, -3.30077380e-01,  7.54410934e+00,\n",
       "        -3.40332508e-01, -3.17623526e-01, -2.87351203e+00,\n",
       "        -2.87292838e-01],\n",
       "       [-1.73967195e+00, -5.30141532e-01,  7.53812504e+00,\n",
       "        -5.31853974e-01, -1.14312947e-01, -2.77804351e+00,\n",
       "        -3.55148494e-01],\n",
       "       [ 4.60237217e+00,  1.19737411e+00, -2.97969913e+00,\n",
       "        -2.54261208e+00, -3.12078333e+00,  3.26383495e+00,\n",
       "        -1.89571112e-01],\n",
       "       [ 1.15529567e-01,  6.61807251e+00, -1.61317909e+00,\n",
       "        -2.03951645e+00, -3.26873112e+00,  1.93000758e+00,\n",
       "        -6.09198689e-01],\n",
       "       [ 6.72417307e+00, -8.00749958e-01, -3.21016121e+00,\n",
       "        -1.01723182e+00, -7.57502079e-01, -5.79867661e-01,\n",
       "        -1.28027296e+00],\n",
       "       [-1.30636573e-01,  2.65651560e+00,  6.32047701e+00,\n",
       "        -1.42880678e+00, -1.62444794e+00, -3.16552806e+00,\n",
       "        -1.23817825e+00],\n",
       "       [-1.70202684e+00, -1.07393503e+00, -3.40774083e+00,\n",
       "        -2.28599238e+00,  1.44150293e+00,  6.55807924e+00,\n",
       "        -7.02437699e-01],\n",
       "       [-2.04566383e+00,  2.60635046e-04,  7.65035295e+00,\n",
       "        -5.51732838e-01, -2.07970724e-01, -2.81909108e+00,\n",
       "        -4.54324335e-01],\n",
       "       [-1.00377774e+00, -1.52518797e+00, -3.52030396e+00,\n",
       "        -2.50640273e+00,  1.09582436e+00,  6.96024609e+00,\n",
       "        -7.58572817e-01],\n",
       "       [ 7.04843426e+00, -2.54932761e-01, -2.19123435e+00,\n",
       "        -2.11356831e+00, -1.38537753e+00, -6.07026398e-01,\n",
       "        -1.06793833e+00],\n",
       "       [ 6.43947792e+00, -1.53206074e+00, -5.16414940e-01,\n",
       "        -4.67913002e-01, -1.42907417e+00, -1.75541222e+00,\n",
       "        -1.11747766e+00],\n",
       "       [-9.25186276e-01, -9.75740552e-01, -3.44000554e+00,\n",
       "        -2.70575476e+00,  6.59598112e-01,  7.04805946e+00,\n",
       "        -8.15768898e-01],\n",
       "       [-1.02486610e+00, -1.69458401e+00, -3.24550366e+00,\n",
       "        -2.85524774e+00,  3.43311429e+00,  5.19332886e+00,\n",
       "        -1.48425770e+00],\n",
       "       [ 9.11011267e-03, -5.27090216e+00, -2.31444860e+00,\n",
       "        -2.00100794e-01,  6.17564869e+00,  2.72533804e-01,\n",
       "        -1.10176170e+00],\n",
       "       [ 1.76609099e-01, -1.32127774e+00, -4.29169750e+00,\n",
       "        -2.76094508e+00,  1.58171260e+00,  6.61744499e+00,\n",
       "        -1.49203587e+00],\n",
       "       [ 6.32691956e+00, -1.97037876e+00, -3.16816306e+00,\n",
       "        -1.43732011e+00,  4.40473389e-03,  2.45555654e-01,\n",
       "        -1.23531592e+00],\n",
       "       [-2.04631066e+00,  1.55933738e-01,  7.57619762e+00,\n",
       "        -4.96775806e-01, -3.91981214e-01, -2.85805130e+00,\n",
       "        -3.46906841e-01],\n",
       "       [ 9.26861644e-01,  7.35389423e+00, -1.05723572e+00,\n",
       "        -1.63543141e+00, -3.86903477e+00,  4.11858708e-01,\n",
       "        -8.35846126e-01],\n",
       "       [ 6.09924221e+00, -2.54157996e+00, -2.72425056e+00,\n",
       "        -2.08215654e-01,  4.88355011e-01, -1.04030442e+00,\n",
       "        -1.19865084e+00],\n",
       "       [ 1.65568972e+00, -1.82464921e+00, -3.85337496e+00,\n",
       "        -2.25797629e+00,  2.98843908e+00,  2.52351189e+00,\n",
       "        -9.96216953e-01],\n",
       "       [ 4.89084148e+00, -3.11438799e+00, -2.87154984e+00,\n",
       "        -1.35382450e+00,  2.08798313e+00,  1.25342309e-01,\n",
       "        -1.47748101e+00],\n",
       "       [ 4.71953106e+00, -6.60791457e-01, -3.28589249e+00,\n",
       "        -2.25957584e+00, -2.07395840e+00,  3.41746044e+00,\n",
       "        -2.28069291e-01],\n",
       "       [-1.99356771e+00,  1.36074051e-01,  7.68288136e+00,\n",
       "        -5.25250912e-01, -4.26660657e-01, -2.94225788e+00,\n",
       "        -2.84395128e-01],\n",
       "       [-1.05341995e+00,  2.55038023e-01,  7.46556091e+00,\n",
       "        -8.70446444e-01, -7.04846680e-01, -3.17778563e+00,\n",
       "        -3.74881297e-01],\n",
       "       [-1.71222878e+00, -2.90360856e+00, -2.59370542e+00,\n",
       "        -2.27638054e+00,  4.39673233e+00,  4.24559879e+00,\n",
       "        -8.95357192e-01],\n",
       "       [-1.73649359e+00, -4.23841524e+00, -9.68548119e-01,\n",
       "        -4.29490924e-01,  6.93512011e+00, -3.26256990e-01,\n",
       "        -1.27331054e+00],\n",
       "       [ 3.93990421e+00,  5.03654003e+00, -1.21414877e-01,\n",
       "        -1.53010726e+00, -4.50633287e+00, -9.62800324e-01,\n",
       "        -7.53539622e-01],\n",
       "       [-2.04805732e+00,  3.56015205e-01, -2.96208644e+00,\n",
       "        -2.04747868e+00, -4.17899311e-01,  6.78583670e+00,\n",
       "        -3.89171541e-01],\n",
       "       [-2.39506796e-01,  7.01117945e+00, -1.06711411e+00,\n",
       "        -2.00616741e+00, -3.15429688e+00,  1.33513713e+00,\n",
       "        -6.97035372e-01],\n",
       "       [-9.55076396e-01, -1.27992356e+00, -3.45875645e+00,\n",
       "        -2.65795088e+00,  7.64159322e-01,  7.03485537e+00,\n",
       "        -6.35373116e-01],\n",
       "       [-2.20999455e+00, -4.28858089e+00, -9.76773441e-01,\n",
       "        -8.87153625e-01,  6.86924124e+00,  6.24533117e-01,\n",
       "        -1.16583788e+00],\n",
       "       [-1.40196669e+00, -1.04497038e-01,  7.56081581e+00,\n",
       "        -4.91715938e-01, -4.11375076e-01, -3.13598728e+00,\n",
       "        -4.76854056e-01],\n",
       "       [-1.83980691e+00, -4.07343268e-01,  7.58130598e+00,\n",
       "        -4.47424918e-01, -1.20813482e-01, -2.77674866e+00,\n",
       "        -4.92290705e-01],\n",
       "       [-1.53964245e+00,  4.92792964e-01,  7.50153971e+00,\n",
       "        -7.12549746e-01, -6.74775064e-01, -3.19256091e+00,\n",
       "        -2.02060223e-01],\n",
       "       [ 7.24623156e+00, -1.08322144e+00, -2.32278490e+00,\n",
       "        -1.57726717e+00, -1.08099365e+00, -6.20255053e-01,\n",
       "        -1.26803315e+00],\n",
       "       [-1.47430182e+00,  2.98822880e-01,  7.63832808e+00,\n",
       "        -4.82333779e-01, -6.04330957e-01, -3.19593740e+00,\n",
       "        -5.22556424e-01],\n",
       "       [-1.27007222e+00, -1.09987557e+00, -3.53838134e+00,\n",
       "        -2.41178894e+00,  9.56689060e-01,  6.88485098e+00,\n",
       "        -6.89152062e-01],\n",
       "       [-3.42185557e-01,  7.07800245e+00, -9.99287963e-01,\n",
       "        -1.91554415e+00, -2.91435432e+00,  8.86103153e-01,\n",
       "        -6.89902306e-01],\n",
       "       [-8.81396294e-01, -1.14384902e+00, -3.37512255e+00,\n",
       "        -2.61782384e+00,  4.04044807e-01,  7.13160324e+00,\n",
       "        -6.59787595e-01],\n",
       "       [-2.30719829e+00, -4.02494478e+00, -6.78658724e-01,\n",
       "        -4.63667274e-01,  6.87229252e+00, -2.50634432e-01,\n",
       "        -1.08252347e+00],\n",
       "       [-4.71482664e-01,  7.57815075e+00, -1.05732314e-01,\n",
       "        -1.51583707e+00, -3.48993802e+00, -1.38435364e-01,\n",
       "        -4.91179466e-01],\n",
       "       [-1.42400503e+00,  7.27549505e+00,  1.67153656e-01,\n",
       "        -1.27566683e+00, -3.18992424e+00,  1.17161423e-01,\n",
       "        -3.83214653e-01],\n",
       "       [ 6.49531555e+00,  1.56567669e+00, -3.82993937e+00,\n",
       "        -1.75868917e+00, -2.06939697e+00,  4.54695106e-01,\n",
       "        -1.34676492e+00],\n",
       "       [-2.08997512e+00, -4.01082945e+00, -9.93234992e-01,\n",
       "        -6.27858222e-01,  6.95621157e+00, -8.49850774e-02,\n",
       "        -1.14693415e+00],\n",
       "       [ 3.12191606e+00,  1.22202635e+00, -2.69812894e+00,\n",
       "        -1.53338373e+00, -2.49879026e+00, -1.77274048e-01,\n",
       "         3.59782481e+00],\n",
       "       [-5.65587521e-01,  7.32044697e+00, -2.96435863e-01,\n",
       "        -1.88012934e+00, -3.72104979e+00,  8.10071588e-01,\n",
       "        -1.38291836e-01],\n",
       "       [-8.20125282e-01, -1.44397950e+00, -3.46678066e+00,\n",
       "        -2.28553534e+00, -5.45428172e-02,  7.03112364e+00,\n",
       "         7.54073188e-02],\n",
       "       [ 6.12578440e+00, -5.61163545e-01, -3.49747682e+00,\n",
       "        -1.63248110e+00, -1.90204918e+00,  4.70527798e-01,\n",
       "         7.11287022e-01],\n",
       "       [ 1.47653484e+00,  4.39254045e+00,  9.67787266e-01,\n",
       "        -2.18681288e+00, -3.56643629e+00, -1.92096984e+00,\n",
       "         2.79223776e+00],\n",
       "       [ 2.19361234e+00,  4.66375208e+00, -1.41777802e+00,\n",
       "        -2.46881270e+00, -3.74004078e+00, -1.83884934e-01,\n",
       "         2.62311721e+00],\n",
       "       [ 1.86506915e+00, -2.00422382e+00, -2.26996112e+00,\n",
       "        -2.34011841e+00,  3.88833910e-01,  5.84587991e-01,\n",
       "         4.04796028e+00],\n",
       "       [-3.97682875e-01,  3.98637891e-01, -3.87924910e+00,\n",
       "        -2.67433691e+00, -8.57946277e-01,  6.55510283e+00,\n",
       "         3.99885118e-01],\n",
       "       [ 4.87686682e+00,  6.82045221e-01, -4.75735378e+00,\n",
       "        -2.17581391e+00, -2.22482061e+00,  3.04844093e+00,\n",
       "         3.01325232e-01],\n",
       "       [ 1.21174252e+00,  4.51511502e-01, -4.55268860e+00,\n",
       "        -2.58878112e+00, -1.13532531e+00,  5.46092033e+00,\n",
       "         7.63074875e-01]], dtype=float32), label_ids=array([4, 1, 4, 0, 0, 3, 1, 0, 2, 5, 5, 0, 0, 0, 5, 0, 0, 1, 0, 0, 4, 2,\n",
       "       3, 0, 0, 3, 2, 3, 4, 0, 0, 5, 4, 2, 3, 3, 0, 2, 5, 2, 1, 0, 0, 5,\n",
       "       0, 5, 0, 0, 0, 5, 5, 2, 5, 5, 0, 5, 2, 2, 0, 1, 0, 2, 5, 2, 5, 0,\n",
       "       0, 5, 5, 4, 0, 0, 2, 1, 0, 5, 0, 0, 2, 2, 5, 4, 0, 5, 1, 5, 4, 2,\n",
       "       2, 2, 0, 2, 0, 1, 5, 4, 1, 1, 0, 4, 1, 1, 3, 4, 0, 0, 6, 0, 0, 4]), metrics={'test_loss': 1.2595199346542358, 'test_f1': 0.7595851570602402, 'test_runtime': 0.5861, 'test_samples_per_second': 187.669, 'test_steps_per_second': 23.885})"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8090909090909091, 0.7595851570602402)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "micro_f1 = f1_score(df_test['labels'],preds[0].argmax(axis = 1), average='micro')\n",
    "macro_f1 = f1_score(df_test['labels'],preds[0].argmax(axis = 1), average='macro')\n",
    "\n",
    "micro_f1, macro_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7 классов\n",
    "# pr_txt f1 = 0.79\n",
    "# pr_txt_cleaned f1 = 0.927\n",
    "# sentences_cleaned f1 = 0.852\n",
    "\n",
    "# 17 классов\n",
    "# pr_txt_cleaned f1 = 0.457"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: lime in /usr/local/lib/python3.10/dist-packages (0.2.0.1)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from lime) (3.8.2)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from lime) (1.26.4)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from lime) (1.12.0)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from lime) (4.66.1)\n",
      "Requirement already satisfied: scikit-learn>=0.18 in /usr/local/lib/python3.10/dist-packages (from lime) (1.2.0)\n",
      "Requirement already satisfied: scikit-image>=0.12 in /usr/local/lib/python3.10/dist-packages (from lime) (0.22.0)\n",
      "Requirement already satisfied: networkx>=2.8 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.12->lime) (3.2.1)\n",
      "Requirement already satisfied: pillow>=9.0.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.12->lime) (10.2.0)\n",
      "Requirement already satisfied: imageio>=2.27 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.12->lime) (2.34.0)\n",
      "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.12->lime) (2024.2.12)\n",
      "Requirement already satisfied: packaging>=21 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.12->lime) (23.2)\n",
      "Requirement already satisfied: lazy_loader>=0.3 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.12->lime) (0.3)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.18->lime) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.18->lime) (3.2.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->lime) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->lime) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->lime) (4.47.2)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->lime) (1.4.5)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->lime) (3.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->lime) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->lime) (1.16.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install lime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2706: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_14351/2333811124.py:16: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  probas = F.softmax(tensor_logits).detach().numpy()\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import lime\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from lime.lime_text import LimeTextExplainer\n",
    "\n",
    "class_names = ['AAA','AA', 'A', 'BBB', 'BB', 'B', 'C']\n",
    "\n",
    "def predictor(texts):\n",
    "    #dataset_tokenized = tokenizer(texts, return_tensors=\"pt\", padding=True)\n",
    "    dataset_tokenized = Dataset.from_dict(dict(tokenizer(texts, return_tensors=\"pt\", padding=True)))\n",
    "    #model.to('cpu')\n",
    "    #outputs = model(dataset_tokenized)\n",
    "    outputs = trainer.predict(dataset_tokenized)\n",
    "    tensor_logits = torch.tensor(outputs[0])\n",
    "    probas = F.softmax(tensor_logits).detach().numpy()\n",
    "    return probas\n",
    "\n",
    "# AA\n",
    "text = '«Эксперт РА» присвоил кредитный рейтинг АО «Просвещение» на уровне <rating>  Москва, 27 декабря 2022 г.  Рейтинговое агентство «Эксперт РА» присвоило  рейтинг кредитоспособности  нефинансовой компании   АО «Просвещение»   на уровне <rating>. Прогноз по рейтингу - стабильный. \") «Просвещение»  — ведущая российская компания, функционирующая в сегменте образования и  предоставляющая продукты и услуги в области печатного и цифрового контента,  повышения квалификации и обучения детей и взрослых, поставок оборудования и  прикладного программного обеспечения в рамках интеграционных проектов в сфере  образования. Компания входит в перечень системообразующих предприятий России и  активно вовлечена в национальные и федеральные образовательные проекты.  Агентство  положительно оценивает рыночные позиции компании, особенно на ключевом для нее  издательском рынке, генерирующим большую часть выручки и EBITDA. Компания занимает первое место  как на рынке учебно-методической литературы (УМЛ), так и по общему тиражу  непериодических изданий среди всех издательств России. «Просвещение» активно  развивает цифровые продукты, что может дополнительно усилить её рыночные  позиции на рынке образования за счёт синергетических эффектов с издательским  бизнесом. Доля цифровых продуктов в выручке пока незначительна, но при этом  сегмент растёт более быстрыми темпами по сравнению с другими бизнесами. На  фактор рыночных позиций, по мнению агентства, оказывает давление концентрация  выручки на сегменте издательской деятельности в сфере образования, на который  приходится более 70% выручки.  В  рамках издательского бизнеса «Просвещение» осуществляет полный цикл по созданию  учебно-методических пособий и их реализации. Компания управляет процессом разработки  учебных пособий, владеет авторскими правами на них, организует их производство  в партнёрских типографиях, обеспечивает поставку учебных изданий в рамках  государственных контрактов с образовательными организациями. Более 40% поставок  приходится на коммерческих клиентов. Бизнес основан на выстраивании  долгосрочных партнёрских отношений с поставщиками и потребителями, поэтому у  компании нет собственных производственных или складских помещений.   «Просвещение»  также занимается оснащением школ учебным оборудованием. Благодаря широкой  партнёрской сети компания может полностью оснащать школы и специализированные  классы необходимым оборудованием, поставлять оборудование в большом объёме и  гарантировать его качество, что выгодно отличает её от более мелких конкурентов.  Рынок оснащения и оборудования школ сильно сегментирован и состоит из большого  количества мелких игроков, что подразумевает более активную конкуренцию.  Барьеры  для входа в отрасль оценены на умеренном уровне, однако новым игрокам рынка  сложно конкурировать по масштабу и экспертизе с «Просвещением», требующим  больших инвестиций в создание продуктов и услуг для образования. Рынок  демонстрирует высокую устойчивость к внешним шокам. Поддержку оценке  устойчивости к внешним шокам'\n",
    "# BB\n",
    "#text = '«Эксперт РА» подтвердил кредитный рейтинг компании ООО «CЕЛЛ-Сервис» на уровне <rating>   Москва, 17 февраля 2023 г.  Рейтинговое агентство «Эксперт РА» подтвердило  рейтинг кредитоспособности  нефинансовой компании   ООО «СЕЛЛ-Сервис»   на уровне <rating>. Прогноз по рейтингу - стабильный.  \") ООО  «СЕЛЛ-Сервис» (далее – компания) специализируется преимущественно на реализации  компонентов, используемых в кондитерской промышленности, а также поставляет  ингредиенты для предприятий молочного производства, производства напитков и  компаний сегмента HoReCa. Компания является поставщиком какао-продуктов,  пищевой химии, ароматизаторов, агар-агаров и пектинов, заквасочных культур,  красителей и карамельного колера, загустителей, наполнителей, замороженного  пюре и одноразовой посуды и упаковки Huhtamaki.   Бизнес-профиль  компании оказывает давление на уровень рейтинга. Подверженность  компании внешним шокам характеризуется как высокая ввиду наличия сильной  зависимости от импортируемых товаров – около 80% всех поставок. Основная часть  импорта приходится на Индонезию (47% всего импорта за 9 месяцев 2022 года),  Китай (28%) и Вьетнам (7%). Отрасль подвержена логистическим рискам на фоне  задержек морских поставок, увеличения сроков разгрузки в портах,  продолжающегося роста стоимости фрахта и недостаточной пропускной способности  железной дороги в России, при этом в условиях геополитического шока 2022 года  компании преимущественно удалось сохранить договорные отношения, сроки и  условия поставок с ключевыми поставщиками и нарастить ассортиментную матрицу. Агентство  отмечает наличие у компании законтрактованных объемов поставок на 2023 год по  основным товарным позициям, что позволяет планировать сроки поступления  продукции для перепродажи. Система расчетов с поставщиками предусматривает  предоплату, в то время как около 70% выручки формируется за счет заказов с  отсрочкой платежа. Законтрактованные с поставщиками объемы импортных закупок  основываются на ретроспективных объемах отгрузок с коэффициентом роста, но при  этом не обеспечены договорными обязательствами с будущими покупателями. Рынок  характеризуется низкими материальными барьерами для входа.  Агентство  оценивает рыночные и конкурентные позиции компании на среднем уровне. Ввиду  небольших текущих масштабов бизнеса позиции на рынках сбыта оцениваются  умеренно-негативно, доля компании по какао-порошку и агар-агарам на рынке  России составляет примерно по 6%, по остальным ключевым товарам не превышает 3%.  Ассортиментный портфель характеризуется умеренно-высокой степенью  диверсификации. Так на крупнейшую номенклатурную позицию – какао-порошок – пришлось  40% от общих продаж, лимонной кислоты – 18%, доли других позиций не превышают 6%.'\n",
    "#print(tokenizer(text, return_tensors='pt', padding=True))\n",
    "\n",
    "explainer = LimeTextExplainer(class_names=class_names)\n",
    "exp = explainer.explain_instance(text, predictor, num_features = 2048, num_samples=1000, top_labels = 7)\n",
    "\n",
    "exp.show_in_notebook(text=text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0d3007d64cea4a50bcf32012fee8d17d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_da4fac23ccbf4c289bc27ede999c2be9",
      "max": 960,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_e2b1dd5ac52f4f1795f3e39bc66b998b",
      "value": 960
     }
    },
    "28f57120d6d84cc2a421a3815fe3d6fe": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_abdebdbc5bad41088115f35fb2f1d5d6",
      "placeholder": "​",
      "style": "IPY_MODEL_673cb2e6bd2c4676ba47d1c072f3675c",
      "value": " 240/240 [00:10&lt;00:00, 23.54 examples/s]"
     }
    },
    "2aaeda6ccd094cc3996cce35823f695e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "2dbe750eb36f44afb572760c6361217e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "20px"
     }
    },
    "37e17a11a1b74296a3ac0af683721623": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4fa69ef96038425196e202e85f65c419",
      "placeholder": "​",
      "style": "IPY_MODEL_2aaeda6ccd094cc3996cce35823f695e",
      "value": " 1200/0 [00:00&lt;00:00, 1996.44 examples/s]"
     }
    },
    "3dcbfc7b131c494facccd1467d5fde0f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "4944065d9f1544a39718986e2e9fe33d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "4bb90ce8f6794cdc80008b0b348332a3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a05b2fe8e9b54d92a2dcbde4d727e66a",
      "placeholder": "​",
      "style": "IPY_MODEL_63a7e6d20dd04a21bdd73f0c5045bd82",
      "value": "Map: 100%"
     }
    },
    "4fa69ef96038425196e202e85f65c419": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5bbe8d24867a4cef9c899bf9b4667665": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_4bb90ce8f6794cdc80008b0b348332a3",
       "IPY_MODEL_8189b7338ace4f379bdbe77dc48b8e7e",
       "IPY_MODEL_28f57120d6d84cc2a421a3815fe3d6fe"
      ],
      "layout": "IPY_MODEL_71952a9a8c944a1783d38195eae1550b"
     }
    },
    "63a7e6d20dd04a21bdd73f0c5045bd82": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "6605ce14652346a182a31dbc69d6db9e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "673cb2e6bd2c4676ba47d1c072f3675c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "71952a9a8c944a1783d38195eae1550b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "75254c71403847e49dfed51646a30bdf": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7b4abf3093c441b98e280cd14256fdd0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "80207e4e50e2459984cf2beab036f66b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2dbe750eb36f44afb572760c6361217e",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_3dcbfc7b131c494facccd1467d5fde0f",
      "value": 1
     }
    },
    "8189b7338ace4f379bdbe77dc48b8e7e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7b4abf3093c441b98e280cd14256fdd0",
      "max": 240,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_4944065d9f1544a39718986e2e9fe33d",
      "value": 240
     }
    },
    "892587c0220b4b739ac6ac653483138f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8be92b5a3a364009b6af55286c91560b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ae212bf556394b92aefa01a0c5274bc7",
      "placeholder": "​",
      "style": "IPY_MODEL_acb512b19fee440880d3ec6864be4669",
      "value": "Generating train split: "
     }
    },
    "8dcd632c9cab4753bdfc157e692e7fca": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a05b2fe8e9b54d92a2dcbde4d727e66a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a3ff77b4fb7c45e7af060e8871e9c1c5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a7d656e93e0c4fbda2ea8226996f7e22": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "abdebdbc5bad41088115f35fb2f1d5d6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "acb512b19fee440880d3ec6864be4669": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ae212bf556394b92aefa01a0c5274bc7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "afdfc15ad67b4088821d3b2d650b88ce": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a7d656e93e0c4fbda2ea8226996f7e22",
      "placeholder": "​",
      "style": "IPY_MODEL_6605ce14652346a182a31dbc69d6db9e",
      "value": " 960/960 [01:01&lt;00:00, 15.59 examples/s]"
     }
    },
    "b07850732b5e43b2971e8e22411ac3f1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_8be92b5a3a364009b6af55286c91560b",
       "IPY_MODEL_80207e4e50e2459984cf2beab036f66b",
       "IPY_MODEL_37e17a11a1b74296a3ac0af683721623"
      ],
      "layout": "IPY_MODEL_892587c0220b4b739ac6ac653483138f"
     }
    },
    "b75811eaa63f40f0bb9a6e908db56001": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_cf10dc85f4054f42afc998c4610cc88f",
       "IPY_MODEL_0d3007d64cea4a50bcf32012fee8d17d",
       "IPY_MODEL_afdfc15ad67b4088821d3b2d650b88ce"
      ],
      "layout": "IPY_MODEL_8dcd632c9cab4753bdfc157e692e7fca"
     }
    },
    "cf10dc85f4054f42afc998c4610cc88f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_75254c71403847e49dfed51646a30bdf",
      "placeholder": "​",
      "style": "IPY_MODEL_a3ff77b4fb7c45e7af060e8871e9c1c5",
      "value": "Map: 100%"
     }
    },
    "da4fac23ccbf4c289bc27ede999c2be9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e2b1dd5ac52f4f1795f3e39bc66b998b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
